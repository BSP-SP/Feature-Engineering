{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "from pandas import read_csv\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(url, header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[:,:13]\n",
    "y=df[:,13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of data before appying LocalOutlierFactor : 506\n",
      "len of data after appying LocalOutlierFactor : 455\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "# fit the model for outlier detection (default)\n",
    "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "# use fit_predict to compute the predicted labels of the training samples\n",
    "# (when LOF is used for outlier detection, the estimator has no predict,\n",
    "# decision_function and score_samples methods).\n",
    "\n",
    "y_pred = clf.fit_predict(x)\n",
    "mask = y_pred != -1\n",
    "\n",
    "x_final,y_final=x[mask,:],y[mask]\n",
    "print(\"len of data before appying LocalOutlierFactor :\",len(x))\n",
    "print(\"len of data after appying LocalOutlierFactor :\",len(x_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of data before appying LocalOutlierFactor : 506\n",
      "len of data after appying LocalOutlierFactor : 455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "clf_svm = OneClassSVM(gamma='auto').fit(x)\n",
    "y_pred_svm=clf.fit_predict(x)\n",
    "mask_svm=y_pred_svm !=-1\n",
    "x_clean,y_clean=x[mask_svm,:],y[mask_svm]\n",
    "print(\"len of data before appying LocalOutlierFactor :\",len(x))\n",
    "print(\"len of data after appying LocalOutlierFactor :\",len(x_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dimensional  Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_7 shape (506, 14)\n",
      "pca_dataset_7 shape (506, 2)\n",
      "inverse_transform_dataset_7 shape (506, 14)\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "# Create PCA with components number\n",
    "pca = KernelPCA(n_components = n_components, kernel=\"rbf\", gamma=0.0433,\n",
    " fit_inverse_transform=True)\n",
    "# fit transform with PCA on dataset\n",
    "pca_dataset_7 = pca.fit_transform(df)\n",
    "# inverse transform back to regular dataset \n",
    "inverse_transform_dataset_7 = pca.inverse_transform(pca_dataset_7)\n",
    "\n",
    "print(\"dataset_7 shape\",df.shape)\n",
    "print(\"pca_dataset_7 shape\",pca_dataset_7.shape)\n",
    "print(\"inverse_transform_dataset_7 shape\",inverse_transform_dataset_7.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the diffrent between X and the inverse_transform_X\n",
    "MSE_score = ((df-inverse_transform_dataset_7)**2).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.20058   0.       18.1       0.        0.713     5.936    80.3\n",
      "   2.7792   24.      666.       20.2       3.5      16.94     13.5    ]\n",
      "[1.3810e-02 8.0000e+01 4.6000e-01 0.0000e+00 4.2200e-01 7.8750e+00\n",
      " 3.2000e+01 5.6484e+00 4.0000e+00 2.5500e+02 1.4400e+01 3.9423e+02\n",
      " 2.9700e+00 5.0000e+01]\n",
      "[4.5900e-02 5.2500e+01 5.3200e+00 0.0000e+00 4.0500e-01 6.3150e+00\n",
      " 4.5600e+01 7.3172e+00 6.0000e+00 2.9300e+02 1.6600e+01 3.9690e+02\n",
      " 7.6000e+00 2.2300e+01]\n",
      "[5.6020e-02 0.0000e+00 2.4600e+00 0.0000e+00 4.8800e-01 7.8310e+00\n",
      " 5.3600e+01 3.1992e+00 3.0000e+00 1.9300e+02 1.7800e+01 3.9263e+02\n",
      " 4.4500e+00 5.0000e+01]\n",
      "[9.6040e-02 4.0000e+01 6.4100e+00 0.0000e+00 4.4700e-01 6.8540e+00\n",
      " 4.2800e+01 4.2673e+00 4.0000e+00 2.5400e+02 1.7600e+01 3.9690e+02\n",
      " 2.9800e+00 3.2000e+01]\n",
      "[1.9657e-01 2.2000e+01 5.8600e+00 0.0000e+00 4.3100e-01 6.2260e+00\n",
      " 7.9200e+01 8.0555e+00 7.0000e+00 3.3000e+02 1.9100e+01 3.7614e+02\n",
      " 1.0150e+01 2.0500e+01]\n",
      "[1.4231e-01 0.0000e+00 1.0010e+01 0.0000e+00 5.4700e-01 6.2540e+00\n",
      " 8.4200e+01 2.2565e+00 6.0000e+00 4.3200e+02 1.7800e+01 3.8874e+02\n",
      " 1.0450e+01 1.8500e+01]\n",
      "[4.83567e+00 0.00000e+00 1.81000e+01 0.00000e+00 5.83000e-01 5.90500e+00\n",
      " 5.32000e+01 3.15230e+00 2.40000e+01 6.66000e+02 2.02000e+01 3.88220e+02\n",
      " 1.14500e+01 2.06000e+01]\n",
      "[  1.00245   0.        8.14      0.        0.538     6.674    87.3\n",
      "   4.239     4.      307.       21.      380.23     11.98     21.     ]\n"
     ]
    }
   ],
   "source": [
    "#taking indices of 9 rows having larger mse\n",
    "import numpy as np\n",
    "ind = np.argpartition(MSE_score, -9)[-9:]\n",
    "for i in ind:\n",
    "    print(df[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
